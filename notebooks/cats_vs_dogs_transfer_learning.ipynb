{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc29b44c-d7d2-4d61-99f9-366a44963d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1984397-e6cb-42cf-a988-f8ffa1dd2e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, val), info = tfds.load(\n",
    "    \"cats_vs_dogs\",\n",
    "    split=[\"train[:80%]\", \"train[80%:]\"],\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9379e7ce-09d3-4674-a69b-0741b2920c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(img, label):\n",
    "    img = tf.image.resize(img, (resolution, resolution)) / 255.0\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15902189-f6d7-4bcd-8071-aff1525edcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "resolution = 224\n",
    "num_examples = info.splits[\"train\"].num_examples\n",
    "\n",
    "train_batches = train.cache().shuffle(num_examples//4).map(image_preprocessing).batch(batch_size).prefetch(1)\n",
    "val_batches = val.cache().map(image_preprocessing).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53914883-0e0e-434f-ba91-0e8643b9f53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 9,679,554\n",
      "Trainable params: 9,679,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(resolution, resolution, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(2, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "753dffe9-8e8c-4172-ae7e-afa0057c0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "380f9a95-2b58-4605-bd1a-b9872d54788e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "582/582 [==============================] - 40s 54ms/step - loss: 0.6766 - accuracy: 0.5719 - val_loss: 0.6376 - val_accuracy: 0.6206\n",
      "Epoch 2/15\n",
      "582/582 [==============================] - 29s 49ms/step - loss: 0.5610 - accuracy: 0.7095 - val_loss: 0.4846 - val_accuracy: 0.7616\n",
      "Epoch 3/15\n",
      "582/582 [==============================] - 28s 48ms/step - loss: 0.4727 - accuracy: 0.7787 - val_loss: 0.3865 - val_accuracy: 0.8323\n",
      "Epoch 4/15\n",
      "582/582 [==============================] - 29s 50ms/step - loss: 0.3948 - accuracy: 0.8257 - val_loss: 0.3610 - val_accuracy: 0.8371\n",
      "Epoch 5/15\n",
      "582/582 [==============================] - 28s 49ms/step - loss: 0.3298 - accuracy: 0.8556 - val_loss: 0.3455 - val_accuracy: 0.8459\n",
      "Epoch 6/15\n",
      "582/582 [==============================] - 28s 49ms/step - loss: 0.2751 - accuracy: 0.8832 - val_loss: 0.3139 - val_accuracy: 0.8654\n",
      "Epoch 7/15\n",
      "582/582 [==============================] - 28s 49ms/step - loss: 0.2263 - accuracy: 0.9092 - val_loss: 0.2986 - val_accuracy: 0.8708\n",
      "Epoch 8/15\n",
      "582/582 [==============================] - 28s 49ms/step - loss: 0.1765 - accuracy: 0.9300 - val_loss: 0.3297 - val_accuracy: 0.8631\n",
      "Epoch 9/15\n",
      "582/582 [==============================] - 28s 49ms/step - loss: 0.1550 - accuracy: 0.9402 - val_loss: 0.3311 - val_accuracy: 0.8807\n",
      "Epoch 10/15\n",
      "582/582 [==============================] - 28s 49ms/step - loss: 0.1361 - accuracy: 0.9474 - val_loss: 0.3354 - val_accuracy: 0.8783\n",
      "Epoch 11/15\n",
      "582/582 [==============================] - 28s 49ms/step - loss: 0.0997 - accuracy: 0.9613 - val_loss: 0.3429 - val_accuracy: 0.8775\n",
      "Epoch 12/15\n",
      "582/582 [==============================] - 28s 49ms/step - loss: 0.0810 - accuracy: 0.9687 - val_loss: 0.3994 - val_accuracy: 0.8674\n",
      "Epoch 13/15\n",
      "582/582 [==============================] - 28s 49ms/step - loss: 0.0739 - accuracy: 0.9743 - val_loss: 0.4684 - val_accuracy: 0.8590\n",
      "Epoch 14/15\n",
      "582/582 [==============================] - 29s 49ms/step - loss: 0.0695 - accuracy: 0.9716 - val_loss: 0.4414 - val_accuracy: 0.8682\n",
      "Epoch 15/15\n",
      "582/582 [==============================] - 30s 52ms/step - loss: 0.0539 - accuracy: 0.9804 - val_loss: 0.4057 - val_accuracy: 0.8751\n"
     ]
    }
   ],
   "source": [
    "number_of_epochs = 15\n",
    "\n",
    "history = model.fit(\n",
    "    train_batches,\n",
    "    epochs=number_of_epochs,\n",
    "    validation_data=val_batches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf556eb2-54af-486c-bafc-2e32b9a25a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "feature_extractor = hub.KerasLayer(url, input_shape=(resolution, resolution, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdaf6668-7505-4657-b417-956b66d227a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "116bf3c7-5db8-4a63-a18c-2edb9dc47776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    feature_extractor,\n",
    "    tf.keras.layers.Dense(2, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a50c89-8ede-4cb8-9aa9-d3164e22c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee0fba24-7723-4da6-b76d-3c9e688a1b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "582/582 [==============================] - 168s 281ms/step - loss: 0.0973 - accuracy: 0.9611 - val_loss: 0.0569 - val_accuracy: 0.9809\n",
      "Epoch 2/3\n",
      "582/582 [==============================] - 95s 164ms/step - loss: 0.0312 - accuracy: 0.9899 - val_loss: 0.0366 - val_accuracy: 0.9877\n",
      "Epoch 3/3\n",
      "582/582 [==============================] - 50s 86ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.0399 - val_accuracy: 0.9865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x298925c5128>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_epochs = 3\n",
    "\n",
    "model.fit(\n",
    "    train_batches,\n",
    "    epochs=number_of_epochs,\n",
    "    validation_data=val_batches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "431e2f23-8bd1-4b99-bd3d-f6705ad2c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = \"./models/cats_vs_dogs_transfer_learning.h5\"\n",
    "model.save(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "408b50c8-d620-46d5-850a-16c4f3050384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "load = tf.keras.models.load_model(\n",
    "    export_path,\n",
    "    custom_objects={\"KerasLayer\": hub.KerasLayer})\n",
    "\n",
    "load.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f84eb01d-12ce-4056-b381-baefd63ba62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = model.predict(val_batches.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "958eaaa2-7f87-4a42-83ec-19e2996979af",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pred = load.predict(val_batches.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "121f3503-63e8-4c9c-be9d-8ed433136fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(model_pred - load_pred)).max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
